{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape NYT\n",
    "\n",
    "This notebook contains code to scrape The New York Times.\n",
    "\n",
    "Caveats:\n",
    "- Some articles in The New York Times are still in their Time Machine and do not have a transcribed copy available. Only their headlines are available. If their headlines happen to contain a deaf-related phrase, my code will include only the headline, and not the body. But if their headlines do not contain a deaf-related phrase, and their body does, my code unfortunately will miss them entirely. \n",
    "\n",
    "Load dependencies and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../config.ini']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "\n",
    "import nltk.data\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import configparser\n",
    "configs = configparser.ConfigParser()\n",
    "configs.read('../../config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>date</th>\n",
       "      <th>doc_type</th>\n",
       "      <th>material_type</th>\n",
       "      <th>news_desk</th>\n",
       "      <th>section</th>\n",
       "      <th>keywords</th>\n",
       "      <th>url</th>\n",
       "      <th>id</th>\n",
       "      <th>byline</th>\n",
       "      <th>deaf_and_dumb</th>\n",
       "      <th>deaf_mute</th>\n",
       "      <th>fell_on_deaf_ears</th>\n",
       "      <th>hearing_impaired</th>\n",
       "      <th>tone_deaf</th>\n",
       "      <th>deaf_as_a_post</th>\n",
       "      <th>stone_deaf</th>\n",
       "      <th>deaf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE DEAF AND DUMB WAITER.</td>\n",
       "      <td>1885-12-03</td>\n",
       "      <td>article</td>\n",
       "      <td>Archives</td>\n",
       "      <td>None</td>\n",
       "      <td>Archives</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.nytimes.com/1885/12/03/archives/th...</td>\n",
       "      <td>nyt://article/0074c23c-1ff6-5bc7-85d9-e56a5af3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chad Threatens to Expel Sudanese Refugees</td>\n",
       "      <td>2006-04-14</td>\n",
       "      <td>article</td>\n",
       "      <td>News</td>\n",
       "      <td>International</td>\n",
       "      <td>World</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.nytimes.com/2006/04/14/world/chad-...</td>\n",
       "      <td>nyt://article/00bb19d7-2ba6-5072-8e6b-3159730d...</td>\n",
       "      <td>By Marc Lacey</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WELFARE HOTEL CHILDREN: TOMORROW'S POOR</td>\n",
       "      <td>1987-07-16</td>\n",
       "      <td>article</td>\n",
       "      <td>News</td>\n",
       "      <td>Metropolitan Desk</td>\n",
       "      <td>New York</td>\n",
       "      <td>[Homeless Persons, HOTELS AND MOTELS, Children...</td>\n",
       "      <td>https://www.nytimes.com/1987/07/16/nyregion/we...</td>\n",
       "      <td>nyt://article/01670df3-ae07-5eb6-8862-7bd834bf...</td>\n",
       "      <td>By Lydia Chavez</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wal-Mart Says Oil Prices Held Down Profits for...</td>\n",
       "      <td>2005-08-16</td>\n",
       "      <td>article</td>\n",
       "      <td>News</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>[Company Reports]</td>\n",
       "      <td>https://www.nytimes.com/2005/08/16/business/wa...</td>\n",
       "      <td>nyt://article/0175ac61-cc62-5cdc-923c-f5efb8ec...</td>\n",
       "      <td>By Roben Farzad</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Space Force? The Idea May Have Merit, Some Say</td>\n",
       "      <td>2018-06-23</td>\n",
       "      <td>article</td>\n",
       "      <td>News</td>\n",
       "      <td>Washington</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>[Space and Astronomy, United States Defense an...</td>\n",
       "      <td>https://www.nytimes.com/2018/06/23/us/politics...</td>\n",
       "      <td>nyt://article/01b8b8a5-7d0c-592a-a283-a9ccd3d8...</td>\n",
       "      <td>By Helene Cooper</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17340</th>\n",
       "      <td>Your Money; Claiming a Pet As a Deduction</td>\n",
       "      <td>1981-03-28</td>\n",
       "      <td>article</td>\n",
       "      <td>News</td>\n",
       "      <td>Financial Desk</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>[ANIMALS, Taxation, Income Tax, Handicapped]</td>\n",
       "      <td>https://www.nytimes.com/1981/03/28/business/yo...</td>\n",
       "      <td>nyt://article/8aa2aceb-e543-5691-b4cc-572cfada...</td>\n",
       "      <td>By Elizabeth M. Fowler</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17341</th>\n",
       "      <td>Your Typical Crowded, Swinging, Silent Bar Scene</td>\n",
       "      <td>1994-10-30</td>\n",
       "      <td>article</td>\n",
       "      <td>News</td>\n",
       "      <td>The City Weekly Desk</td>\n",
       "      <td>New York</td>\n",
       "      <td>[Deafness, Bars]</td>\n",
       "      <td>https://www.nytimes.com/1994/10/30/nyregion/ne...</td>\n",
       "      <td>nyt://article/1aab92b9-5b05-50b7-bf7a-2b8cef19...</td>\n",
       "      <td>By Jennifer Kingson Bloom</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17342</th>\n",
       "      <td>‘Fargo’ Recap: Dead Dogs, Spiders and Pestilence</td>\n",
       "      <td>2014-04-30</td>\n",
       "      <td>article</td>\n",
       "      <td>News</td>\n",
       "      <td>Culture</td>\n",
       "      <td>Arts</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://artsbeat.blogs.nytimes.com/2014/04/29/...</td>\n",
       "      <td>nyt://article/3a6161c6-023a-5968-a28e-0ea2ecb6...</td>\n",
       "      <td>By Kate Phillips</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17343</th>\n",
       "      <td>‘Singing’ With Their Hands</td>\n",
       "      <td>2012-02-11</td>\n",
       "      <td>article</td>\n",
       "      <td>News</td>\n",
       "      <td>Styles</td>\n",
       "      <td>Fashion &amp; Style</td>\n",
       "      <td>[Video Recordings and Downloads, Music, Sign L...</td>\n",
       "      <td>https://www.nytimes.com/2012/02/12/fashion/sin...</td>\n",
       "      <td>nyt://article/0918d106-bd33-59fe-a100-cd3f9a23...</td>\n",
       "      <td>By Austin Considine</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17344</th>\n",
       "      <td>‘Switched at Birth,’ a Series Illuminating a W...</td>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>article</td>\n",
       "      <td>News</td>\n",
       "      <td>Culture</td>\n",
       "      <td>Arts</td>\n",
       "      <td>[Television]</td>\n",
       "      <td>https://www.nytimes.com/2017/01/30/arts/televi...</td>\n",
       "      <td>nyt://article/70949850-b6e8-50c9-9982-1061b7f8...</td>\n",
       "      <td>By Neil Genzlinger</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17345 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline       date doc_type  \\\n",
       "0                              THE DEAF AND DUMB WAITER. 1885-12-03  article   \n",
       "1              Chad Threatens to Expel Sudanese Refugees 2006-04-14  article   \n",
       "2                WELFARE HOTEL CHILDREN: TOMORROW'S POOR 1987-07-16  article   \n",
       "3      Wal-Mart Says Oil Prices Held Down Profits for... 2005-08-16  article   \n",
       "4       A Space Force? The Idea May Have Merit, Some Say 2018-06-23  article   \n",
       "...                                                  ...        ...      ...   \n",
       "17340          Your Money; Claiming a Pet As a Deduction 1981-03-28  article   \n",
       "17341   Your Typical Crowded, Swinging, Silent Bar Scene 1994-10-30  article   \n",
       "17342   ‘Fargo’ Recap: Dead Dogs, Spiders and Pestilence 2014-04-30  article   \n",
       "17343                         ‘Singing’ With Their Hands 2012-02-11  article   \n",
       "17344  ‘Switched at Birth,’ a Series Illuminating a W... 2017-01-30  article   \n",
       "\n",
       "      material_type             news_desk          section  \\\n",
       "0          Archives                  None         Archives   \n",
       "1              News         International            World   \n",
       "2              News     Metropolitan Desk         New York   \n",
       "3              News              Business     Business Day   \n",
       "4              News            Washington             U.S.   \n",
       "...             ...                   ...              ...   \n",
       "17340          News        Financial Desk     Business Day   \n",
       "17341          News  The City Weekly Desk         New York   \n",
       "17342          News               Culture             Arts   \n",
       "17343          News                Styles  Fashion & Style   \n",
       "17344          News               Culture             Arts   \n",
       "\n",
       "                                                keywords  \\\n",
       "0                                                     []   \n",
       "1                                                     []   \n",
       "2      [Homeless Persons, HOTELS AND MOTELS, Children...   \n",
       "3                                      [Company Reports]   \n",
       "4      [Space and Astronomy, United States Defense an...   \n",
       "...                                                  ...   \n",
       "17340       [ANIMALS, Taxation, Income Tax, Handicapped]   \n",
       "17341                                   [Deafness, Bars]   \n",
       "17342                                                 []   \n",
       "17343  [Video Recordings and Downloads, Music, Sign L...   \n",
       "17344                                       [Television]   \n",
       "\n",
       "                                                     url  \\\n",
       "0      https://www.nytimes.com/1885/12/03/archives/th...   \n",
       "1      https://www.nytimes.com/2006/04/14/world/chad-...   \n",
       "2      https://www.nytimes.com/1987/07/16/nyregion/we...   \n",
       "3      https://www.nytimes.com/2005/08/16/business/wa...   \n",
       "4      https://www.nytimes.com/2018/06/23/us/politics...   \n",
       "...                                                  ...   \n",
       "17340  https://www.nytimes.com/1981/03/28/business/yo...   \n",
       "17341  https://www.nytimes.com/1994/10/30/nyregion/ne...   \n",
       "17342  https://artsbeat.blogs.nytimes.com/2014/04/29/...   \n",
       "17343  https://www.nytimes.com/2012/02/12/fashion/sin...   \n",
       "17344  https://www.nytimes.com/2017/01/30/arts/televi...   \n",
       "\n",
       "                                                      id  \\\n",
       "0      nyt://article/0074c23c-1ff6-5bc7-85d9-e56a5af3...   \n",
       "1      nyt://article/00bb19d7-2ba6-5072-8e6b-3159730d...   \n",
       "2      nyt://article/01670df3-ae07-5eb6-8862-7bd834bf...   \n",
       "3      nyt://article/0175ac61-cc62-5cdc-923c-f5efb8ec...   \n",
       "4      nyt://article/01b8b8a5-7d0c-592a-a283-a9ccd3d8...   \n",
       "...                                                  ...   \n",
       "17340  nyt://article/8aa2aceb-e543-5691-b4cc-572cfada...   \n",
       "17341  nyt://article/1aab92b9-5b05-50b7-bf7a-2b8cef19...   \n",
       "17342  nyt://article/3a6161c6-023a-5968-a28e-0ea2ecb6...   \n",
       "17343  nyt://article/0918d106-bd33-59fe-a100-cd3f9a23...   \n",
       "17344  nyt://article/70949850-b6e8-50c9-9982-1061b7f8...   \n",
       "\n",
       "                          byline  deaf_and_dumb  deaf_mute  fell_on_deaf_ears  \\\n",
       "0                            NaN           True      False              False   \n",
       "1                  By Marc Lacey           True      False              False   \n",
       "2                By Lydia Chavez           True      False              False   \n",
       "3                By Roben Farzad           True      False              False   \n",
       "4               By Helene Cooper           True      False              False   \n",
       "...                          ...            ...        ...                ...   \n",
       "17340     By Elizabeth M. Fowler          False      False              False   \n",
       "17341  By Jennifer Kingson Bloom          False      False              False   \n",
       "17342           By Kate Phillips          False      False              False   \n",
       "17343        By Austin Considine          False      False              False   \n",
       "17344         By Neil Genzlinger          False      False              False   \n",
       "\n",
       "       hearing_impaired  tone_deaf  deaf_as_a_post  stone_deaf   deaf  \n",
       "0                 False      False           False       False  False  \n",
       "1                 False      False           False       False  False  \n",
       "2                 False      False           False       False  False  \n",
       "3                 False      False           False       False  False  \n",
       "4                 False      False           False       False  False  \n",
       "...                 ...        ...             ...         ...    ...  \n",
       "17340              True      False           False       False   True  \n",
       "17341              True      False           False       False   True  \n",
       "17342              True      False           False       False   True  \n",
       "17343              True      False           False       False   True  \n",
       "17344              True      False           False       False   True  \n",
       "\n",
       "[17345 rows x 18 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/all.csv')\n",
    "data['keywords'] = data['keywords'].apply(literal_eval)\n",
    "data['date'] = pd.to_datetime(data['date']) \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deaf_and_dumb': ['deaf and dumb', 'deaf dumb'],\n",
       " 'deaf_mute': ['deaf mute', 'deaf and mute', 'mute deaf', 'mute and deaf'],\n",
       " 'fell_on_deaf_ears': ['fell on deaf ears',\n",
       "  'fall on deaf ears',\n",
       "  'falls on deaf ears',\n",
       "  'fall on a deaf ear',\n",
       "  'falling on deaf ears',\n",
       "  'falling on a deaf ear',\n",
       "  'turn a deaf ear',\n",
       "  'turned deaf ears',\n",
       "  'turned a deaf ear',\n",
       "  'turning deaf ears',\n",
       "  'turning a deaf ear'],\n",
       " 'hearing_impaired': ['hearing impaired', 'hearing impairment'],\n",
       " 'tone_deaf': ['tone deaf'],\n",
       " 'deaf_as_a_post': ['deaf as a post'],\n",
       " 'stone_deaf': ['stone deaf'],\n",
       " 'deaf': ['deaf']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('phrases.txt', 'r') as infile:\n",
    "    phrases = json.load(infile)\n",
    "    \n",
    "phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract data subset for only the True/False columns. We use this when scraping to see which phrases each article has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_subset = data.loc[:, 'deaf_and_dumb':'deaf']\n",
    "column_names = data_subset.columns.values.astype(str)\n",
    "phrases_for_each_article = [column_names[i].tolist() for i in data_subset.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape sentences into sentences vector/Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to log into the New York Times site, browse to each article, and scrape matching sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_nyt():\n",
    "    # Open browser and navigate to NYT\n",
    "    browser = webdriver.Chrome(executable_path='../../chromedriver')\n",
    "    browser.get('https://nyt.com')\n",
    "\n",
    "    # Bring up login portal\n",
    "    wait = WebDriverWait(browser, 15)\n",
    "    login_button_XPATH = '//button[@data-testid=\"login-button\"]'\n",
    "    login_button_present = EC.presence_of_element_located((By.XPATH, login_button_XPATH))\n",
    "    login_button = wait.until(login_button_present)\n",
    "    login_button.click()\n",
    "\n",
    "    # Log in\n",
    "    fields_present = EC.presence_of_element_located((By.ID, 'username'))\n",
    "    wait.until(fields_present).send_keys(configs['NYT']['EMAIL'])\n",
    "    browser.find_element_by_id('password').send_keys(configs['NYT']['PASSWORD'])\n",
    "    browser.find_element_by_xpath(login_button_XPATH).click()\n",
    "    \n",
    "    return browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paragraphs():\n",
    "    '''Returns a list of the paragraphs on the page.'''\n",
    "    paragraphs = browser.find_elements_by_tag_name('p')\n",
    "    text = []\n",
    "    try:\n",
    "        if '/video/' in browser.current_url:\n",
    "            print('Page contains a video.')\n",
    "            text = [h2.text for h2 in browser.find_elements_by_tag_name('h2')]\n",
    "        else:\n",
    "            text = [p.text for p in paragraphs]\n",
    "    except StaleElementReferenceException:\n",
    "        print('StaleElementReferenceException')\n",
    "        text = get_paragraphs()\n",
    "        \n",
    "    return text\n",
    "\n",
    "\n",
    "def scrape_matches(article, only_do_headline=False):\n",
    "    matches = []\n",
    "    \n",
    "    # Get all paragraphs\n",
    "    if not only_do_headline:    \n",
    "        paragraphs = get_paragraphs()     \n",
    "        paragraphs.append(article['headline']) # add headline to paragraphs\n",
    "    else:\n",
    "        if not isinstance(article['headline'], pd.Series) and math.isnan(article['headline']):\n",
    "            return matches\n",
    "        else:\n",
    "            paragraphs = [article['headline']]\n",
    "    paragraphs_cleaned = [' '.join(RegexpTokenizer(r'\\w+').tokenize(p)).lower() for p in paragraphs] # remove punctuation, lowercase\n",
    "\n",
    "    # Get all varieties of the phrases for this article\n",
    "    phrases_for_this_article = phrases_for_each_article[article.name]\n",
    "    phrase_varieties = ['deaf'] # add by default, also because we made the 'deaf' column to exclude other 'deaf' terms\n",
    "    for phrase in phrases_for_this_article:\n",
    "        phrase_varieties += [x for x in phrases[phrase]]\n",
    "\n",
    "    # Get sentences that contain a phrase variety\n",
    "    for p in phrase_varieties:\n",
    "        matches += ([paragraphs[i] for i, x in enumerate(paragraphs_cleaned) if (p in x and paragraphs[i] not in matches)])\n",
    "\n",
    "    return matches\n",
    "\n",
    "    \n",
    "def scrape(article):\n",
    "    time.sleep(5)\n",
    "    article_id = article['id']\n",
    "    url = article['url']\n",
    "    status = None\n",
    "    matches = None\n",
    "    statuses = ['Full text is unavailable for this digitized archive article.',\n",
    "              'Page Not Found',\n",
    "              'Server Error',\n",
    "              'Success',\n",
    "              'Failed',\n",
    "              'We’re sorry, we seem to be having some technical difficulties, but we don’t want to lose you.']\n",
    "    \n",
    "    # Navigate to page\n",
    "    browser.get(article['url'])\n",
    "    \n",
    "    # If Error 503, refresh\n",
    "    if \"Error 503 first byte timeout\" in browser.page_source:\n",
    "        print('Error 503')\n",
    "        browser.refresh()\n",
    "    \n",
    "    # If video in URL\n",
    "    if '/video/' in article['url']:\n",
    "        status = statuses[3] # success\n",
    "        matches = scrape_matches(article) # scrape the article\n",
    "        if len(matches) >= 1: \n",
    "            status = statuses[3]\n",
    "            print(status + ': ' + str(len(matches)) + ' paragraph(s) found.') \n",
    "        else:\n",
    "            status = statuses[4]\n",
    "            matches = None\n",
    "            print(status) # failed\n",
    "    \n",
    "    elif statuses[0] in browser.page_source: # time machine\n",
    "        status = statuses[0]\n",
    "        matches = scrape_matches(article) # will only attempt to scrape headline\n",
    "        if len(matches) >= 1:\n",
    "            print(status + ': ' + str(len(matches)) + ' paragraph(s) found.') \n",
    "        else:\n",
    "            matches = None\n",
    "            print(status)\n",
    "            \n",
    "    elif statuses[1] in browser.page_source: \n",
    "        status = statuses[1] # page not found\n",
    "        matches = scrape_matches(article, True)\n",
    "        if len(matches) >= 1:\n",
    "            print(status + ': ' + str(len(matches)) + ' paragraph(s) found.')\n",
    "        else:\n",
    "            matches = None\n",
    "            print(status)\n",
    "    \n",
    "    elif statuses[2] in browser.page_source or statuses[5] in browser.page_source: \n",
    "        status = statuses[2] # server error\n",
    "        matches = scrape_matches(article, True)\n",
    "        if len(matches) >= 1:\n",
    "            print(status + ': ' + str(len(matches)) + ' paragraph(s) found.')\n",
    "        else:\n",
    "            matches = None\n",
    "            print(status)\n",
    "        \n",
    "    else:\n",
    "        status = statuses[3] # success\n",
    "        matches = scrape_matches(article) # scrape the article\n",
    "        if len(matches) >= 1: \n",
    "            status = statuses[3]\n",
    "            print(status + ': ' + str(len(matches)) + ' paragraph(s) found.') \n",
    "        else:\n",
    "            status = statuses[4]\n",
    "            matches = None\n",
    "            print(status) # failed\n",
    "            \n",
    "    return article_id, status, matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape sentences. We get back two lists, `statuses` and `sentences`.\n",
    "\n",
    "`sentences` is a 2D list with all the sentences found for each article, including the headline if it matched. \n",
    "\n",
    "`statuses` is a 1D list with the scrape status for each article:\n",
    "- `Page Not Found` — if the page was not found\n",
    "- `Full text is unavailable for this digitized archive article.` — if there is no fulltext available, and the article needs to be viewed through Time Machine\n",
    "- `Server Errror` — if there was a server error on NYT's side\n",
    "- `Success` \n",
    "- `Failed` — if the page was fine, but my logic failed to find a matching sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = connect_to_nyt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Updated data/paragraphs.csv\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Updated data/paragraphs.csv\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Updated data/paragraphs.csv\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 2 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Updated data/paragraphs.csv\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 2 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Updated data/paragraphs.csv\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 2 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 2 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Updated data/paragraphs.csv\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 2 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Updated data/paragraphs.csv\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 2 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Updated data/paragraphs.csv\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 2 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Updated data/paragraphs.csv\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Updated data/paragraphs.csv\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Updated data/paragraphs.csv\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 3 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Success: 1 paragraph(s) found.\n",
      "Updated data/paragraphs.csv\n",
      "Success: 1 paragraph(s) found.\n"
     ]
    }
   ],
   "source": [
    "def chunker(df, size):\n",
    "    return (df[pos:pos + size] for pos in range(0, len(df), size))\n",
    "\n",
    "csv_path = 'data/paragraphs.csv'\n",
    "if os.path.exists(csv_path):\n",
    "    already_scraped = pd.read_csv('data/paragraphs.csv')\n",
    "    not_yet_scraped = data[~data['id'].isin(already_scraped['id'])]\n",
    "else:\n",
    "    not_yet_scraped = data\n",
    "    \n",
    "article_iterator = chunker(not_yet_scraped, 10)\n",
    "\n",
    "for chunk in article_iterator:\n",
    "    ids, statuses, paragraphs = zip(*chunk.apply(scrape, axis=1))\n",
    "    if not os.path.exists(csv_path):\n",
    "        include_header = True\n",
    "        mode = 'w'\n",
    "    else: \n",
    "        include_header = False\n",
    "        mode = 'a'\n",
    "        with open(csv_path, 'a') as f:\n",
    "            f.write('\\n') # buggy if i don't do this, idk why, will concatenate 1st line on last line\n",
    "    pd.DataFrame({'id': ids, 'status': statuses, 'sentences': paragraphs}).to_csv(csv_path, index=False, header=include_header, mode=mode)\n",
    "    print('Updated ' + csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To do:**\n",
    "- For the articles that are unavailable as fulltexts, I can collect their URLs based on sentences==None then maybe automatically direct browser to the TimeMachine, then I will manually read it then [type the sentence into Jupyter Notebook using user input](https://stackoverflow.com/questions/34968112/how-to-give-jupyter-cell-standard-input-in-python) and then the program will add this to sentences cell for that article row, move on to the next row that needs it, then redirect browser automatically, and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline = data[data['url'] == 'https://www.nytimes.com/1998/06/22//IHT-william-at-16-prince-of-hearts-and-new-windsor-icon.html']['headline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4308    William at 16: Prince of Hearts and New Windso...\n",
       "Name: headline, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4308    William at 16: Prince of Hearts and New Windso...\n",
       "Name: headline, dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(headline, pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
